{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5K_DFxAuwvz"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pickle\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from music21 import instrument, note, stream, chord,converter\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import BatchNormalization as BatchNorm\n",
        "from keras.layers import Activation\n",
        "import glob\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0zdnL_E0EO-"
      },
      "outputs": [],
      "source": [
        "with open('/content/notes', 'rb') as filepath:\n",
        "        notes = pickle.load(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M25NJ0K90Fcj"
      },
      "outputs": [],
      "source": [
        "pitch = sorted(set(i for i in notes))\n",
        "n_vocab = len(pitch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TX8wwnro1Ptq"
      },
      "outputs": [],
      "source": [
        "note_int = dict((i, n) for n, i in enumerate(pitch))\n",
        "seq_l = 100\n",
        "input,output = [],[]\n",
        "for i in range(len(notes) - seq_l):\n",
        "    temp = notes[i:i+seq_l]\n",
        "    input.append([note_int[j] for j in temp])\n",
        "    output.append(note_int[notes[i+seq_l]])\n",
        "\n",
        "norm_input = np.reshape(input, (-1, seq_l, 1))\n",
        "norm_output = np.reshape(output, (-1, 1))\n",
        "norm_input = norm_input / float(n_vocab)\n",
        "norm_output = norm_output/float(n_vocab)\n",
        "norm_output2 = norm_output*float(n_vocab)\n",
        "norm_output1 = keras.utils.np_utils.to_categorical(norm_output2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKsLtB6o1JoW",
        "outputId": "a172cab3-f247-4717-89b5-60ba147412e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "435/435 [==============================] - 165s 368ms/step - loss: 4.8674 - lr: 0.0500\n",
            "Epoch 2/10\n",
            "435/435 [==============================] - ETA: 0s - loss: 4.8982\n",
            "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
            "435/435 [==============================] - 160s 368ms/step - loss: 4.8982 - lr: 0.0500\n",
            "Epoch 3/10\n",
            "435/435 [==============================] - 160s 369ms/step - loss: 4.6651 - lr: 0.0125\n",
            "Epoch 4/10\n",
            "435/435 [==============================] - 161s 370ms/step - loss: 4.6536 - lr: 0.0125\n",
            "Epoch 5/10\n",
            "435/435 [==============================] - 162s 372ms/step - loss: 4.6469 - lr: 0.0125\n",
            "Epoch 6/10\n",
            "435/435 [==============================] - ETA: 0s - loss: 4.6483\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0031250000465661287.\n",
            "435/435 [==============================] - 159s 366ms/step - loss: 4.6483 - lr: 0.0125\n",
            "Epoch 7/10\n",
            "435/435 [==============================] - 161s 369ms/step - loss: 4.6036 - lr: 0.0031\n",
            "Epoch 8/10\n",
            "435/435 [==============================] - 160s 367ms/step - loss: 4.6017 - lr: 0.0031\n",
            "Epoch 9/10\n",
            "435/435 [==============================] - ETA: 0s - loss: 4.6020\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0007812500116415322.\n",
            "435/435 [==============================] - 167s 384ms/step - loss: 4.6020 - lr: 0.0031\n",
            "Epoch 10/10\n",
            "435/435 [==============================] - 160s 368ms/step - loss: 4.5919 - lr: 7.8125e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7d8b401ece50>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(512,input_shape=(norm_input.shape[1], norm_input.shape[2]),recurrent_dropout=0.3,\n",
        "        return_sequences=True))\n",
        "model.add(LSTM(300))\n",
        "model.add(BatchNorm())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(n_vocab))\n",
        "model.add(Activation('softmax'))\n",
        "callbacks = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\",factor=0.25,patience=1,verbose=1,)\n",
        "Adam = tf.keras.optimizers.Adam(learning_rate=0.05)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam)\n",
        "model.fit(norm_input,norm_output1  ,epochs=10, batch_size=64, verbose = 1,callbacks = [callbacks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMjgTX1WHh-D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "608b7796-494a-4c46-af90-e0b69bccc0aa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ce8483d8-d83c-479d-8301-7af5dc819111\", \"song2_model_512512512densedense_200e.h5\", 65775648)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.save('song2_model_512512512densedense_200e.h5')\n",
        "# model = keras.models.load_model('hi.h5')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('song2_model_512512512densedense_200e.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3OfgzNv3fEb"
      },
      "outputs": [],
      "source": [
        "start = np.random.randint(0, len(input)-1)\n",
        "int_note = dict((n, i) for n, i in enumerate(pitch))\n",
        "p = input[start]\n",
        "pred = []\n",
        "for i in range(500):\n",
        "    temp = np.reshape(p, (1, len(p), 1))\n",
        "    temp = temp / float(n_vocab)\n",
        "\n",
        "    temp_p = model.predict(temp, verbose=0)\n",
        "\n",
        "    index = np.argmax(temp_p)\n",
        "    try:\n",
        "      result = int_note[index]\n",
        "    except:\n",
        "      result = int_note[0]\n",
        "    pred.append(result)\n",
        "\n",
        "    p.append(index)\n",
        "    p = p[1:len(p)]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpyQAvBV43ic",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "046f9999-1abd-40c0-f7af-eea980736e0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'test_output1.mid'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "offset = 0\n",
        "pred_notes = []\n",
        "for i in pred:\n",
        "        # chord\n",
        "        if ('.' in i) or i.isdigit():\n",
        "            chord_l = i.split('.')\n",
        "            notes1 = []\n",
        "            for j in chord_l:\n",
        "                temp = note.Note(int(j))\n",
        "                temp.storedInstrument = instrument.Piano()\n",
        "                notes1.append(temp)\n",
        "            new_chord = chord.Chord(notes1)\n",
        "            new_chord.offset = offset\n",
        "            pred_notes.append(new_chord)\n",
        "        # note\n",
        "        else:\n",
        "            temp = note.Note(i)\n",
        "            temp.offset = offset\n",
        "            temp.storedInstrument = instrument.Piano()\n",
        "            pred_notes.append(temp)\n",
        "\n",
        "        offset += 0.5\n",
        "\n",
        "midi_stream = stream.Stream(pred_notes)\n",
        "midi_stream.write('midi', fp='test_output1.mid')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('test_output1.mid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "p5ifsdSVF2dl",
        "outputId": "1c14905f-e03a-4a1c-ef36-6845bb099432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0b767c34-2ffe-4b0a-b53b-c14f69bbebf8\", \"test_output1.mid\", 4628)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMvsuNLoKiLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69bbac7b-e42d-4de5-e8b3-6fc9a554d5f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(set(pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlUNQ4BIK0z5",
        "outputId": "db6ccb83-8fa0-4718-ce67-8d6eda36ddf6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "435/435 [==============================] - 173s 387ms/step - loss: 4.7039 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "435/435 [==============================] - 161s 369ms/step - loss: 4.4435 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "435/435 [==============================] - 162s 371ms/step - loss: 4.4233 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "435/435 [==============================] - 161s 370ms/step - loss: 4.4001 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "435/435 [==============================] - 161s 370ms/step - loss: 4.4378 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "435/435 [==============================] - ETA: 0s - loss: 4.4094\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "435/435 [==============================] - 160s 367ms/step - loss: 4.4094 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "435/435 [==============================] - 158s 363ms/step - loss: 4.3868 - lr: 5.0000e-04\n",
            "Epoch 8/10\n",
            "435/435 [==============================] - 161s 368ms/step - loss: 4.3656 - lr: 5.0000e-04\n",
            "Epoch 9/10\n",
            "435/435 [==============================] - 163s 373ms/step - loss: 4.3488 - lr: 5.0000e-04\n",
            "Epoch 10/10\n",
            "435/435 [==============================] - 160s 369ms/step - loss: 4.3386 - lr: 5.0000e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7d8ab8748af0>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(512,input_shape=(norm_input.shape[1], norm_input.shape[2]),recurrent_dropout=0.3,\n",
        "        return_sequences=True))\n",
        "model.add(LSTM(300))\n",
        "model.add(BatchNorm())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(n_vocab))\n",
        "model.add(Activation('softmax'))\n",
        "callbacks = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\",factor=0.5,patience=2,verbose=1)\n",
        "# Adam = tf.keras.optimizers.Adam(learning_rate=0.05)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.fit(norm_input,norm_output1  ,epochs=10, batch_size=64, verbose = 1,callbacks = [callbacks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOZOAqd903uq",
        "outputId": "551d318c-25e4-43f4-d00f-84c02a69890f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "435/435 [==============================] - 168s 375ms/step - loss: 2.3905 - lr: 5.0000e-04\n",
            "Epoch 2/50\n",
            "435/435 [==============================] - 161s 371ms/step - loss: 2.3435 - lr: 5.0000e-04\n",
            "Epoch 3/50\n",
            "435/435 [==============================] - 162s 372ms/step - loss: 2.2985 - lr: 5.0000e-04\n",
            "Epoch 4/50\n",
            "435/435 [==============================] - 164s 377ms/step - loss: 2.2511 - lr: 5.0000e-04\n",
            "Epoch 5/50\n",
            "435/435 [==============================] - 162s 372ms/step - loss: 2.2038 - lr: 5.0000e-04\n",
            "Epoch 6/50\n",
            "435/435 [==============================] - 161s 371ms/step - loss: 2.1711 - lr: 5.0000e-04\n",
            "Epoch 7/50\n",
            "435/435 [==============================] - 161s 370ms/step - loss: 2.1253 - lr: 5.0000e-04\n",
            "Epoch 8/50\n",
            "435/435 [==============================] - 162s 373ms/step - loss: 2.0948 - lr: 5.0000e-04\n",
            "Epoch 9/50\n",
            "435/435 [==============================] - 163s 374ms/step - loss: 2.0633 - lr: 5.0000e-04\n",
            "Epoch 10/50\n",
            "435/435 [==============================] - 162s 373ms/step - loss: 2.0230 - lr: 5.0000e-04\n",
            "Epoch 11/50\n",
            "435/435 [==============================] - 164s 376ms/step - loss: 2.0074 - lr: 5.0000e-04\n",
            "Epoch 12/50\n",
            "435/435 [==============================] - 162s 373ms/step - loss: 1.9550 - lr: 5.0000e-04\n",
            "Epoch 13/50\n",
            "435/435 [==============================] - 162s 372ms/step - loss: 1.9300 - lr: 5.0000e-04\n",
            "Epoch 14/50\n",
            "435/435 [==============================] - 162s 371ms/step - loss: 1.8856 - lr: 5.0000e-04\n",
            "Epoch 15/50\n",
            "435/435 [==============================] - 161s 371ms/step - loss: 1.8505 - lr: 5.0000e-04\n",
            "Epoch 16/50\n",
            "435/435 [==============================] - 161s 371ms/step - loss: 1.8196 - lr: 5.0000e-04\n",
            "Epoch 17/50\n",
            "435/435 [==============================] - 161s 369ms/step - loss: 1.7785 - lr: 5.0000e-04\n",
            "Epoch 18/50\n",
            "435/435 [==============================] - 162s 372ms/step - loss: 1.7566 - lr: 5.0000e-04\n",
            "Epoch 19/50\n",
            "435/435 [==============================] - 165s 380ms/step - loss: 1.7251 - lr: 5.0000e-04\n",
            "Epoch 20/50\n",
            "435/435 [==============================] - 162s 372ms/step - loss: 1.6834 - lr: 5.0000e-04\n",
            "Epoch 21/50\n",
            "435/435 [==============================] - 162s 372ms/step - loss: 1.6595 - lr: 5.0000e-04\n",
            "Epoch 22/50\n",
            "435/435 [==============================] - 163s 376ms/step - loss: 1.6196 - lr: 5.0000e-04\n",
            "Epoch 23/50\n",
            "435/435 [==============================] - 165s 381ms/step - loss: 1.5968 - lr: 5.0000e-04\n",
            "Epoch 24/50\n",
            "435/435 [==============================] - 164s 376ms/step - loss: 1.5711 - lr: 5.0000e-04\n",
            "Epoch 25/50\n",
            "435/435 [==============================] - 163s 375ms/step - loss: 1.5509 - lr: 5.0000e-04\n",
            "Epoch 26/50\n",
            "435/435 [==============================] - 166s 382ms/step - loss: 1.5175 - lr: 5.0000e-04\n",
            "Epoch 27/50\n",
            "435/435 [==============================] - 165s 380ms/step - loss: 1.4940 - lr: 5.0000e-04\n",
            "Epoch 28/50\n",
            "435/435 [==============================] - 165s 380ms/step - loss: 1.4805 - lr: 5.0000e-04\n",
            "Epoch 29/50\n",
            "435/435 [==============================] - 167s 384ms/step - loss: 1.4475 - lr: 5.0000e-04\n",
            "Epoch 30/50\n",
            "435/435 [==============================] - 165s 380ms/step - loss: 1.4254 - lr: 5.0000e-04\n",
            "Epoch 31/50\n",
            "435/435 [==============================] - 173s 398ms/step - loss: 1.4066 - lr: 5.0000e-04\n",
            "Epoch 32/50\n",
            "435/435 [==============================] - 174s 399ms/step - loss: 1.3866 - lr: 5.0000e-04\n",
            "Epoch 33/50\n",
            "435/435 [==============================] - 170s 390ms/step - loss: 1.3509 - lr: 5.0000e-04\n",
            "Epoch 34/50\n",
            "435/435 [==============================] - 173s 398ms/step - loss: 1.3355 - lr: 5.0000e-04\n",
            "Epoch 35/50\n",
            "435/435 [==============================] - 169s 389ms/step - loss: 1.3167 - lr: 5.0000e-04\n",
            "Epoch 36/50\n",
            "435/435 [==============================] - 169s 389ms/step - loss: 1.2851 - lr: 5.0000e-04\n",
            "Epoch 37/50\n",
            "435/435 [==============================] - 169s 389ms/step - loss: 1.2625 - lr: 5.0000e-04\n",
            "Epoch 38/50\n",
            "435/435 [==============================] - 166s 382ms/step - loss: 1.2487 - lr: 5.0000e-04\n",
            "Epoch 39/50\n",
            "435/435 [==============================] - 168s 386ms/step - loss: 1.2319 - lr: 5.0000e-04\n",
            "Epoch 40/50\n",
            "435/435 [==============================] - 165s 380ms/step - loss: 1.1938 - lr: 5.0000e-04\n",
            "Epoch 41/50\n",
            "435/435 [==============================] - 167s 385ms/step - loss: 1.1805 - lr: 5.0000e-04\n",
            "Epoch 42/50\n",
            "435/435 [==============================] - 168s 386ms/step - loss: 1.1685 - lr: 5.0000e-04\n",
            "Epoch 43/50\n",
            "435/435 [==============================] - 169s 390ms/step - loss: 1.1370 - lr: 5.0000e-04\n",
            "Epoch 44/50\n",
            "435/435 [==============================] - 168s 387ms/step - loss: 1.1264 - lr: 5.0000e-04\n",
            "Epoch 45/50\n",
            "435/435 [==============================] - 167s 385ms/step - loss: 1.1102 - lr: 5.0000e-04\n",
            "Epoch 46/50\n",
            "435/435 [==============================] - 166s 382ms/step - loss: 1.0917 - lr: 5.0000e-04\n",
            "Epoch 47/50\n",
            "435/435 [==============================] - 167s 384ms/step - loss: 1.0728 - lr: 5.0000e-04\n",
            "Epoch 48/50\n",
            "435/435 [==============================] - 167s 384ms/step - loss: 1.0572 - lr: 5.0000e-04\n",
            "Epoch 49/50\n",
            "435/435 [==============================] - 168s 387ms/step - loss: 1.0494 - lr: 5.0000e-04\n",
            "Epoch 50/50\n",
            "435/435 [==============================] - 168s 387ms/step - loss: 1.0256 - lr: 5.0000e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7e2f416493c0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "callbacks = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\",factor=0.5,patience=2,verbose=1)\n",
        "model.fit(norm_input,norm_output1  ,epochs=50, batch_size=64, verbose = 1,callbacks = [callbacks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mawk6Se31v0p",
        "outputId": "200bb63c-a69d-4ecd-8c25-7add8b0164b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "435/435 [==============================] - 343s 762ms/step - loss: 4.5930 - lr: 5.0000e-04\n",
            "Epoch 2/10\n",
            "435/435 [==============================] - ETA: 0s - loss: 4.5939\n",
            "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "435/435 [==============================] - 341s 783ms/step - loss: 4.5939 - lr: 5.0000e-04\n",
            "Epoch 3/10\n",
            "435/435 [==============================] - 331s 762ms/step - loss: 4.5914 - lr: 2.5000e-04\n",
            "Epoch 4/10\n",
            "435/435 [==============================] - 327s 752ms/step - loss: 4.5899 - lr: 2.5000e-04\n",
            "Epoch 5/10\n",
            "435/435 [==============================] - ETA: 0s - loss: 4.6139\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "435/435 [==============================] - 324s 744ms/step - loss: 4.6139 - lr: 2.5000e-04\n",
            "Epoch 6/10\n",
            "435/435 [==============================] - 325s 747ms/step - loss: 4.5063 - lr: 1.2500e-04\n",
            "Epoch 7/10\n",
            "435/435 [==============================] - 327s 751ms/step - loss: 4.4748 - lr: 1.2500e-04\n",
            "Epoch 8/10\n",
            "435/435 [==============================] - 324s 746ms/step - loss: 4.4596 - lr: 1.2500e-04\n",
            "Epoch 9/10\n",
            "435/435 [==============================] - 326s 749ms/step - loss: 4.4412 - lr: 1.2500e-04\n",
            "Epoch 10/10\n",
            "435/435 [==============================] - 344s 790ms/step - loss: 4.4208 - lr: 1.2500e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7dfd041f1390>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#30\n",
        "callbacks = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\",factor=0.5,patience=1,verbose=1)\n",
        "model.fit(norm_input,norm_output1  ,epochs=10, batch_size=64, verbose = 1,callbacks = [callbacks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPzws_btuR7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcaf1207-eb3f-4796-848e-789f48fe1aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "435/435 [==============================] - 346s 767ms/step - loss: 4.4041 - lr: 1.2500e-04\n",
            "Epoch 2/10\n",
            "435/435 [==============================] - 344s 792ms/step - loss: 4.3781 - lr: 1.2500e-04\n",
            "Epoch 3/10\n",
            "435/435 [==============================] - 332s 764ms/step - loss: 4.3609 - lr: 1.2500e-04\n",
            "Epoch 4/10\n",
            "435/435 [==============================] - 334s 769ms/step - loss: 4.3312 - lr: 1.2500e-04\n",
            "Epoch 5/10\n",
            "435/435 [==============================] - 337s 775ms/step - loss: 4.3080 - lr: 1.2500e-04\n",
            "Epoch 6/10\n",
            "435/435 [==============================] - 337s 774ms/step - loss: 4.2850 - lr: 1.2500e-04\n",
            "Epoch 7/10\n",
            "435/435 [==============================] - 334s 768ms/step - loss: 4.2556 - lr: 1.2500e-04\n",
            "Epoch 8/10\n",
            "435/435 [==============================] - 336s 772ms/step - loss: 4.2228 - lr: 1.2500e-04\n",
            "Epoch 9/10\n",
            "435/435 [==============================] - 340s 782ms/step - loss: 4.1909 - lr: 1.2500e-04\n",
            "Epoch 10/10\n",
            "435/435 [==============================] - 332s 764ms/step - loss: 4.1569 - lr: 1.2500e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7cd28136dab0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#40\n",
        "callbacks = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\",factor=0.5,patience=1,verbose=1)\n",
        "model.fit(norm_input,norm_output1  ,epochs=10, batch_size=64, verbose = 1,callbacks = [callbacks])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#50\n",
        "callbacks = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\",factor=0.5,patience=1,verbose=1)\n",
        "model.fit(norm_input,norm_output1  ,epochs=10, batch_size=64, verbose = 1,callbacks = [callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zRfHCAc1dBz",
        "outputId": "cfe07886-47a4-412f-81a9-f7e27939ecd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "435/435 [==============================] - 331s 760ms/step - loss: 4.1144 - lr: 1.2500e-04\n",
            "Epoch 2/10\n",
            "435/435 [==============================] - 331s 761ms/step - loss: 4.0824 - lr: 1.2500e-04\n",
            "Epoch 3/10\n",
            "435/435 [==============================] - 331s 762ms/step - loss: 4.0508 - lr: 1.2500e-04\n",
            "Epoch 4/10\n",
            "435/435 [==============================] - 330s 760ms/step - loss: 4.0110 - lr: 1.2500e-04\n",
            "Epoch 5/10\n",
            "435/435 [==============================] - 333s 766ms/step - loss: 3.9874 - lr: 1.2500e-04\n",
            "Epoch 6/10\n",
            "435/435 [==============================] - 334s 767ms/step - loss: 3.9507 - lr: 1.2500e-04\n",
            "Epoch 7/10\n",
            "435/435 [==============================] - 332s 763ms/step - loss: 3.9165 - lr: 1.2500e-04\n",
            "Epoch 8/10\n",
            "435/435 [==============================] - 330s 760ms/step - loss: 3.8872 - lr: 1.2500e-04\n",
            "Epoch 9/10\n",
            "435/435 [==============================] - 331s 760ms/step - loss: 3.8520 - lr: 1.2500e-04\n",
            "Epoch 10/10\n",
            "435/435 [==============================] - 342s 785ms/step - loss: 3.8173 - lr: 1.2500e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7cd2803173a0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#112\n",
        "callbacks = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\",factor=0.5,patience=1,verbose=1)\n",
        "model.fit(norm_input,norm_output1  ,epochs=12, batch_size=64, verbose = 1,callbacks = [callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mwLmP3rD7hh",
        "outputId": "9ced4968-daef-4a1e-874b-c72fe0caba92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "435/435 [==============================] - 363s 807ms/step - loss: 1.8501 - lr: 1.2500e-04\n",
            "Epoch 2/12\n",
            "435/435 [==============================] - 344s 791ms/step - loss: 1.8348 - lr: 1.2500e-04\n",
            "Epoch 3/12\n",
            "435/435 [==============================] - 342s 787ms/step - loss: 1.8053 - lr: 1.2500e-04\n",
            "Epoch 4/12\n",
            "435/435 [==============================] - 349s 803ms/step - loss: 1.7695 - lr: 1.2500e-04\n",
            "Epoch 5/12\n",
            "435/435 [==============================] - 350s 804ms/step - loss: 1.7481 - lr: 1.2500e-04\n",
            "Epoch 6/12\n",
            "435/435 [==============================] - 346s 796ms/step - loss: 1.7273 - lr: 1.2500e-04\n",
            "Epoch 7/12\n",
            "435/435 [==============================] - 343s 789ms/step - loss: 1.6993 - lr: 1.2500e-04\n",
            "Epoch 8/12\n",
            "435/435 [==============================] - 343s 787ms/step - loss: 1.6607 - lr: 1.2500e-04\n",
            "Epoch 9/12\n",
            "435/435 [==============================] - 347s 799ms/step - loss: 1.6287 - lr: 1.2500e-04\n",
            "Epoch 10/12\n",
            "435/435 [==============================] - 346s 795ms/step - loss: 1.6015 - lr: 1.2500e-04\n",
            "Epoch 11/12\n",
            "435/435 [==============================] - 347s 798ms/step - loss: 1.5819 - lr: 1.2500e-04\n",
            "Epoch 12/12\n",
            "435/435 [==============================] - 344s 790ms/step - loss: 1.5641 - lr: 1.2500e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7dea1e345a20>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#200\n",
        "callbacks = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\",factor=0.5,patience=1,verbose=1)\n",
        "model.fit(norm_input,norm_output1  ,epochs=25, batch_size=64, verbose = 1,callbacks = [callbacks])"
      ],
      "metadata": {
        "id": "U46_y6FjW-ny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2946a1c6-55ba-41f8-fa25-fe9829dd20b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "435/435 [==============================] - 331s 737ms/step - loss: 0.5206 - lr: 1.2500e-04\n",
            "Epoch 2/25\n",
            "435/435 [==============================] - 324s 744ms/step - loss: 0.5189 - lr: 1.2500e-04\n",
            "Epoch 3/25\n",
            "435/435 [==============================] - 324s 746ms/step - loss: 0.4947 - lr: 1.2500e-04\n",
            "Epoch 4/25\n",
            "435/435 [==============================] - ETA: 0s - loss: 0.4995\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "435/435 [==============================] - 345s 793ms/step - loss: 0.4995 - lr: 1.2500e-04\n",
            "Epoch 5/25\n",
            "435/435 [==============================] - 325s 747ms/step - loss: 0.4241 - lr: 6.2500e-05\n",
            "Epoch 6/25\n",
            "435/435 [==============================] - 322s 740ms/step - loss: 0.4008 - lr: 6.2500e-05\n",
            "Epoch 7/25\n",
            "435/435 [==============================] - 331s 760ms/step - loss: 0.3858 - lr: 6.2500e-05\n",
            "Epoch 8/25\n",
            "435/435 [==============================] - 330s 758ms/step - loss: 0.3798 - lr: 6.2500e-05\n",
            "Epoch 9/25\n",
            "435/435 [==============================] - ETA: 0s - loss: 0.3821\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "435/435 [==============================] - 326s 751ms/step - loss: 0.3821 - lr: 6.2500e-05\n",
            "Epoch 10/25\n",
            "435/435 [==============================] - 322s 741ms/step - loss: 0.3424 - lr: 3.1250e-05\n",
            "Epoch 11/25\n",
            "435/435 [==============================] - ETA: 0s - loss: 0.3434\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "435/435 [==============================] - 323s 743ms/step - loss: 0.3434 - lr: 3.1250e-05\n",
            "Epoch 12/25\n",
            "435/435 [==============================] - 323s 742ms/step - loss: 0.3251 - lr: 1.5625e-05\n",
            "Epoch 13/25\n",
            "435/435 [==============================] - 320s 736ms/step - loss: 0.3148 - lr: 1.5625e-05\n",
            "Epoch 14/25\n",
            "435/435 [==============================] - 322s 740ms/step - loss: 0.3135 - lr: 1.5625e-05\n",
            "Epoch 15/25\n",
            "435/435 [==============================] - 319s 734ms/step - loss: 0.3132 - lr: 1.5625e-05\n",
            "Epoch 16/25\n",
            "435/435 [==============================] - 320s 734ms/step - loss: 0.3072 - lr: 1.5625e-05\n",
            "Epoch 17/25\n",
            "435/435 [==============================] - 318s 732ms/step - loss: 0.3021 - lr: 1.5625e-05\n",
            "Epoch 18/25\n",
            "435/435 [==============================] - ETA: 0s - loss: 0.3075\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "435/435 [==============================] - 319s 733ms/step - loss: 0.3075 - lr: 1.5625e-05\n",
            "Epoch 19/25\n",
            "435/435 [==============================] - 318s 732ms/step - loss: 0.2944 - lr: 7.8125e-06\n",
            "Epoch 20/25\n",
            "435/435 [==============================] - 320s 736ms/step - loss: 0.2923 - lr: 7.8125e-06\n",
            "Epoch 21/25\n",
            "435/435 [==============================] - 320s 736ms/step - loss: 0.2921 - lr: 7.8125e-06\n",
            "Epoch 22/25\n",
            "435/435 [==============================] - 318s 730ms/step - loss: 0.2851 - lr: 7.8125e-06\n",
            "Epoch 23/25\n",
            "435/435 [==============================] - ETA: 0s - loss: 0.2975\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "435/435 [==============================] - 319s 732ms/step - loss: 0.2975 - lr: 7.8125e-06\n",
            "Epoch 24/25\n",
            "435/435 [==============================] - 324s 745ms/step - loss: 0.2843 - lr: 3.9063e-06\n",
            "Epoch 25/25\n",
            "435/435 [==============================] - 319s 733ms/step - loss: 0.2821 - lr: 3.9063e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7e84a22ae800>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2m79R2MgBtqI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}